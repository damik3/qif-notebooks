{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Differential Privacy_ and _Quantitative Information Flow_ can be seen as having essentially the same goal, namely to control the leakage of sensitive information. In this notebook, we are going to try to explore similarities and differences bewteen the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from func import *\n",
    "try:\n",
    "    from qif import *\n",
    "except: # install qif if not available (for running in colab, etc)\n",
    "    import IPython; IPython.get_ipython().run_line_magic('pip', 'install qif')\n",
    "    from qif import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example scenario\n",
    "\n",
    "Assume we are interested in the eye color of a certain population $\\cal{I} = \\{Alice,Bob,Charlie\\}$. Let the possible values for each person in $\\cal{I}$ be defined by the set $\\cal{V}=\\{a,b,g\\}$, where $a$ stands for absent (i.e. the person is not in this specific database), $b$ stands for _black_ and $g$ for _green_. Each dataset is a tuple $x_0x_1x_2 \\in \\cal{V}^2$ where $x_0$ represents the eye color of _Alice_, $x_1$ of _Bob_ and $x_2$ of _Charlie_. \n",
    "\n",
    "The possible values of $X$ are\n",
    "\n",
    "```\n",
    "X = { \n",
    "    aaa, aab, aag, \n",
    "    aba, abb, abg,\n",
    "    aga, agb, agg,\n",
    "    baa, bab, bag,\n",
    "         ...\n",
    "    gga, ggb, ggg\n",
    "    }\n",
    "```\n",
    "\n",
    "Consider the following counting query.\n",
    "\n",
    "```\n",
    "SELECT COUNT(*)\n",
    "FROM X\n",
    "WHERE eye_color = 'b';\n",
    "```\n",
    "\n",
    "Its possible output values are\n",
    "\n",
    "```\n",
    "Y = {0, 1, 2, 3}\n",
    "```\n",
    "\n",
    "We can model this query as a deterministic channel $f$ as below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "f & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{aaa} & 1 & 0 & 0 & 0  \\\\ \\hline\n",
    "\\texttt{aab} & 0 & 1 & 0 & 0  \\\\ \\hline \n",
    "\\texttt{aag} & 1 & 0 & 0 & 0  \\\\ \\hline \n",
    "\\texttt{aba} & 0 & 1 & 0 & 0  \\\\ \\hline \n",
    "... & ... & ... & ... & ...\\\\ \\hline\n",
    "\\texttt{ggg} & 1 & 0 & 0 & 0  \\\\ \\hline \n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now insted of reporting the true answer $y$, we process it further by passing it through a noise channel $H$ and report a slightly different answer $z$. \n",
    "\n",
    "Here are gonna use the following mechanism for $H$.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "H & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{0} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{1} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "\\texttt{2} & \\frac{1}{12} & \\frac{1}{6} & \\frac{1}{2} & \\frac{1}{4} \\\\ \\hline\n",
    "\\texttt{3} & \\frac{1}{36} & \\frac{1}{18} & \\frac{1}{6} & \\frac{3}{4} \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "What $H$ does is basically add noise to the true answer of $f$ using a specific logic which is not of importance for this example. The thing to notice is that the true answer of $f$ has the highest probability within its row.\n",
    "\n",
    "So the whole channel, from $X$ to $Z$, i.e. from the database to the fuzzy query answer, can be depicted as below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "C & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{aaa} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{aab} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "\\texttt{aag} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{aba} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "... & ... & ... & ... & ...\\\\ \\hline\n",
    "\\texttt{ggg} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline \n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_persons = 3\n",
    "values = ['a', 'b', 'g']\n",
    "num_values = len(values)\n",
    "query_value = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.02777778 0.05555556 0.16666667 0.75      ]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]]\n"
     ]
    }
   ],
   "source": [
    "C = get_C(num_persons, values, query_value)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that $Z$ can also occur from the matrix multiplication of $f$ and $H$, that is\n",
    "\n",
    "$$\n",
    "f \\cdot H = Z\n",
    "$$\n",
    "\n",
    "The following image graphically depicts the whole setting (ingore the notions of leakage and utility for now).\n",
    "\n",
    "![img1](./img1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing information leakage through _QIF_\n",
    "\n",
    "To measure the leakage with _QIF_ we must first define the prior distribution $\\pi$ over $X$. If we don't have any particular knowledge about it we use the uniform distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704]\n"
     ]
    }
   ],
   "source": [
    "pi = probab.uniform(num_persons ** num_values)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the posterior distributions which depend both on $C$ and $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|    0.35    0.31    0.21    0.13 |\n",
      "---------------------------------------\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.00    0.01    0.03    0.22 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from print_hyper import print_hyper\n",
    "print_hyper(C, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each column of the matrix above, i.e. each possible outcome $z$, __QIF__ models the threat as the highest probability within that column, i.e. the probability of sucess of the best possible guess for which database $x$ we are dealing with. So we pick the maximum probability for each column and then **we weigh** each one with its respective outer probability, i.e. the probability of each $z$ occuring. And the result is the vulnerability of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIF posterior vulnerability: 0.09259259259259259\n"
     ]
    }
   ],
   "source": [
    "print(\"QIF posterior vulnerability:\", measure.bayes_vuln.posterior(pi, C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing information leakage through _Differential Privacy_\n",
    "\n",
    "Differential privacy works a bit differently. \n",
    "\n",
    "First of all, it uses the notion of _adjacent_ or _neighbor_ databases. This means two databases that differ in the presence of, or in the value associated with, exactly one individual. We use $x_1 \\sim x_2$ to indicate that $x_1$ and $x_2$ are adjacent. For example $bbg \\sim bag$ and $aba \\sim bba$ but $bba \\nsim bgb$.\n",
    "\n",
    "Now, for each column of $C$, i.e. each possible outcome $z$, __Differential Privacy__ models the threat as the biggest difference between any two _adjacent_ databases and computes the gap bewteen them as below\n",
    "\n",
    "$$\n",
    "C_{x_1z} \\cdot e^{\\epsilon} = C_{x_2z} \n",
    "$$\n",
    "\n",
    "where the biggest gap between any two _adjacent_ elements of that column is realized for $x_1$ and $x_2$ and $C_{x_1z}$ is the smallest probability and $C_{x_2z}$ the biggest.\n",
    "\n",
    "To combine the $\\epsilon$ values for all $z$, we keep the biggest one, which represents the biggest gap between the probabilities of any two _adjacent_ elements for all columns of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon: 3.295836866004329\n"
     ]
    }
   ],
   "source": [
    "# The following function overestimates the real value of epsilon,\n",
    "# but provides an upper bound for it.\n",
    "print(\"Differential Privacy epsilon:\", get_worst_epsilon(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that indeed that is the worst-case $\\epsilon$ by observing the $\\epsilon$ values for each column of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon for column 0 = 3.295836866004329\n",
      "epsilon for column 1 = 2.1972245773362196\n",
      "epsilon for column 2 = 2.1972245773362196\n",
      "epsilon for column 3 = 3.295836866004329\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_values+1):\n",
    "    print(\"epsilon for column\", i, \"=\", get_worst_epsilon(C, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the two approaches\n",
    "\n",
    "First of all let's consider the basic ideas behind each approach.\n",
    "\n",
    "**QIF** vulnerablity measures the probability that an adversary has of correctly guessing the secret $x$ (i.e. the whole database in our case) upon observing the channel's output $z$. \n",
    "\n",
    "**$\\epsilon$-differential privacy**'s basic idea on the other hand, is that that the presence or absence of any individual in a database, or changing the data of any individual, should not significantly affect the probability of obtaining any specific answer for a certain query.\n",
    "\n",
    "So clearly, they don't have the same goal or the same adversary in mind.\n",
    "\n",
    "Going a little further we see that QIF vulnerability is sensitive to the prior distribution of $X$ whereas $\\epsilon$-differential privacy is not.\n",
    "\n",
    "For example consider the uniform and point distrubtions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi1\n",
      " [0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704] \n",
      "\n",
      "pi2\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pi1 = probab.uniform(num_persons ** num_values)\n",
    "print(\"pi1\\n\", pi1, \"\\n\")\n",
    "pi2 = probab.point(num_persons ** num_values)\n",
    "print(\"pi2\\n\", pi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we measure the information leakage thrgouh QIF for both cases we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIF posterior vulnerability for p1: 0.09259259259259259\n",
      "QIF posterior vulnerability for p2: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"QIF posterior vulnerability for p1:\", measure.bayes_vuln.posterior(pi1, C))\n",
    "print(\"QIF posterior vulnerability for p2:\", measure.bayes_vuln.posterior(pi2, C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But differential privacy does not consider the prior distribution of $X$, so we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon for pi1: 3.295836866004329\n",
      "Differential Privacy epsilon for pi2: 3.295836866004329\n"
     ]
    }
   ],
   "source": [
    "print(\"Differential Privacy epsilon for pi1:\", get_worst_epsilon(C))\n",
    "print(\"Differential Privacy epsilon for pi2:\", get_worst_epsilon(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is also obvious from the fact that the `get_worst_epsilon` function does not take a `pi` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another difference between the two is that QIF vulnerability is defined as the result of averagind the contribution of all the columns to the vulnerability, while differential privacy represents the worst case (i.e.the maximum $\\epsilon$ for all $z$).\n",
    "\n",
    "Hence there could be a column with a very high $\\epsilon$ value which does not contribute very much to the average (typically because the corresponding output has very low probability of happening). In that case, QIF vulnerability could be very small, and still $\\epsilon$-differential privacy would have a really big $\\epsilon$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating ideas from QIF into Differential Privacy\n",
    "\n",
    "It is interesting to notice that since differential privacy does not take into account the prior distribution, we could use a prior uniform distribution, which assumes no special knowledge about $X$, and then compute the epsilon parameter from the posterior distributions matrix like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon: 3.2958368660043296\n"
     ]
    }
   ],
   "source": [
    "pi = probab.uniform(num_persons ** num_values)\n",
    "posteriors = channel.hyper(C, pi)[1]\n",
    "print(\"Differential Privacy epsilon:\", get_worst_epsilon(posteriors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel matrix $C$ and the matrix of the posterior distributions give the same epsilon values for all columns. Compare them with the results we got before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon for column 0 = 3.2958368660043296\n",
      "epsilon for column 1 = 2.1972245773362196\n",
      "epsilon for column 2 = 2.1972245773362196\n",
      "epsilon for column 3 = 3.2958368660043296\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_values+1):\n",
    "    print(\"epsilon for column\", i, \"=\", get_worst_epsilon(posteriors, column=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if for some reason, there is a need to take the prior distribution into account, we could define $\\pi$ and $C$ and compute the epsilon value from the matrix of the posterior distributions which is sensitive to changes in $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to address the last difference we mentioned before between the two methods, it would be interesting to consider that instead of taking the worst-case $\\epsilon$ for all columns, we could weigh the $\\epsilon$ of each column with its respective outer probability (i.e. the probability of each $z$ happening). This way we would not let low-probability high-impact $\\epsilon$ affect too much the general leakage of our mechanism.\n",
    "\n",
    "In that scenario $\\epsilon$ would be computed as below.\n",
    "\n",
    "$$\n",
    "\\epsilon = p_Z(z_0) \\cdot \\epsilon_0 + p_Z(z_1) \\cdot \\epsilon_1 + p_Z(z_2) \\cdot \\epsilon_2 + p_Z(z_3) \\cdot \\epsilon_3\n",
    "$$\n",
    "\n",
    "Again, if we don't want to incorporate any special knowledge about the prior distribution we could assume the uniform distribution.\n",
    "\n",
    "So the new $\\epsilon$ for our example would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon: 2.7261860496579025\n"
     ]
    }
   ],
   "source": [
    "p_z = channel.hyper(C, pi)[0]\n",
    "e = 0\n",
    "\n",
    "for i in range(num_values+1):\n",
    "    e += p_z[i] * get_worst_epsilon(posteriors, column=i)\n",
    "\n",
    "print(\"Differential Privacy epsilon:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is obviously lower than the $\\epsilon$ we calculated before, since that one represents the worst case over all columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
