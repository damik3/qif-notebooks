{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Differential Privacy_ and _Quantitative Information Flow_ can be seen as having essentially the same goal, namely to control the leakage of sensitive information. In this notebook, we are going to try to explore similarities and differences bewteen the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from func import *\n",
    "try:\n",
    "    from qif import *\n",
    "except: # install qif if not available (for running in colab, etc)\n",
    "    import IPython; IPython.get_ipython().run_line_magic('pip', 'install qif')\n",
    "    from qif import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example scenario\n",
    "\n",
    "Assume we are interested in the eye color of a certain population $\\cal{I} = \\{Alice,Bob,Charlie\\}$. Let the possible values for each person in $\\cal{I}$ be defined by the set $\\cal{V}=\\{a,b,g\\}$, where $a$ stands for absent (i.e. the person is not in this specific database), $b$ stands for _black_ and $g$ for _green_. Each dataset is a tuple $x_0x_1x_2 \\in \\cal{V}^2$ where $x_0$ represents the eye color of _Alice_, $x_1$ of _Bob_ and $x_2$ of _Charlie_. \n",
    "\n",
    "So we have\n",
    "\n",
    "```\n",
    "X = { \n",
    "    aaa, aab, aag, \n",
    "    aba, abb, abg,\n",
    "    aga, agb, agg,\n",
    "    baa, bab, bag,\n",
    "         ...\n",
    "    gga, ggb, ggg\n",
    "    }\n",
    "```\n",
    "\n",
    "Consider now a counting query in the form of\n",
    "\n",
    "```\n",
    "SELECT COUNT(*)\n",
    "FROM X\n",
    "WHERE eye_color = 'b';\n",
    "```\n",
    "\n",
    "Its possible output values are\n",
    "\n",
    "```\n",
    "Y = {0, 1, 2, 3}\n",
    "```\n",
    "\n",
    "We can model this query as a channel $f$ as below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "f & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{aaa} & 1 & 0 & 0 & 0  \\\\ \\hline\n",
    "\\texttt{aab} & 0 & 1 & 0 & 0  \\\\ \\hline \n",
    "\\texttt{aag} & 1 & 0 & 0 & 0  \\\\ \\hline \n",
    "\\texttt{aba} & 0 & 1 & 0 & 0  \\\\ \\hline \n",
    "... & ... & ... & ... & ...\\\\ \\hline\n",
    "\\texttt{ggg} & 1 & 0 & 0 & 0  \\\\ \\hline \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Now insted of reporting the true answer $y$, we process it further by passing it through a noise channel $H$ and report a slightly different answer $z$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are gonna use the following mechanism for $H$.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "H & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{0} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{1} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "\\texttt{2} & \\frac{1}{12} & \\frac{1}{6} & \\frac{1}{2} & \\frac{1}{4} \\\\ \\hline\n",
    "\\texttt{3} & \\frac{1}{36} & \\frac{1}{18} & \\frac{1}{6} & \\frac{3}{4} \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "What $H$ does is basically add noise to the true answer of $f$ using a specific logic which is not of importance for this example. The thing to notice is that the true answer of $f$ has the highest probability within its row.\n",
    "\n",
    "So the whole channel, from $X$ to $Z$, i.e. from the database to the fuzzy query answer, can be depicted as below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "C & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{aaa} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{aab} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "\\texttt{aag} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{aba} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "... & ... & ... & ... & ...\\\\ \\hline\n",
    "\\texttt{ggg} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_persons = 3\n",
    "values = ['a', 'b', 'g']\n",
    "num_values = len(values)\n",
    "query_value = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.02777778 0.05555556 0.16666667 0.75      ]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]]\n"
     ]
    }
   ],
   "source": [
    "C = get_C(num_persons, values, query_value)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image graphically depicts the whole setting (ingore the notions of leakage and utility for now).\n",
    "\n",
    "![img1](./img1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing the information leakage through _QIF_\n",
    "\n",
    "To measure the leakage with _QIF_ we must first define the prior distribution over $X$. If we don't have any particular knowledge about it we use the uniform distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704]\n"
     ]
    }
   ],
   "source": [
    "pi = probab.uniform(num_persons ** num_values)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the hyper distribution which depends both on $H$ and $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|    0.35    0.31    0.21    0.13 |\n",
      "---------------------------------------\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.00    0.01    0.03    0.22 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from print_hyper import print_hyper\n",
    "print_hyper(C, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each column of the matrix above, i.e. each possible outcome $z$, __QIF__ models the threat as the $x$ with the highest probability within that column. So we pick the maximum probabilities of each column and then **we weigh** them with the outer probabilities, i.e. the probability of each $z$ occuring. And the result is the vulnerability of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIF posterior vulnerability: 0.09259259259259259\n"
     ]
    }
   ],
   "source": [
    "print(\"QIF posterior vulnerability:\", measure.bayes_vuln.posterior(pi, C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesing the information leakage through _Differential Privacy_\n",
    "\n",
    "Differential privacy works a bit differently. \n",
    "\n",
    "First of all, it uses the notion of _adjacent_ or _neighbor_ databases. This means two databases that differ in the presence of, or in the value associated with, exactly one individual. We use $x_1 \\sim x_2$ to indicate that $x_1$ and $x_2$ are adjacent. For example $bbg \\sim bag$ and $aba \\sim bba$.\n",
    "\n",
    "Now, for each column of $C$, i.e. each possible outcome $z$, __Differential Privacy__ models the threat as the biggest difference between any two _adjacent_ databases and computes the gap bewteen them as below.\n",
    "\n",
    "$$\n",
    "C_{x_1z} \\cdot e^{\\epsilon} = C_{x_2z} \n",
    "$$\n",
    "\n",
    "where the biggest gap between any two _adjacent_ elements of that column is realized for $x_1$ and $x_2$ and $C_{x_1z}$ is the smallest probability and $C_{x_2z}$ is the highest.\n",
    "\n",
    "To combine the $\\epsilon$ values for all $z$, we keep the biggest one, which represents the biggest gap between the probabilities of any two _adjacent_ elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon: 3.295836866004329\n"
     ]
    }
   ],
   "source": [
    "# The following function overestimates the real value of epsilon,\n",
    "# but provides an upper bound for it.\n",
    "print(\"Differential Privacy epsilon:\", get_worst_epsilon(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that indeed that is the worst-case $\\epsilon$ by observing the $\\epsilon$ values for each column of $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon for column 0 = 3.295836866004329\n",
      "epsilon for column 1 = 2.1972245773362196\n",
      "epsilon for column 2 = 2.1972245773362196\n",
      "epsilon for column 3 = 3.295836866004329\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_values+1):\n",
    "    print(\"epsilon for column\", i, \"=\", get_worst_epsilon(C, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind **Differential Privacy** is that the presence or absence of any individual in a database, or changing the data of any individual, does not significantly affect the probability of obtaining any specific answer for a certain query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the two approaches\n",
    "\n",
    "One difference is that QIF is sensitive to the prior distribution of $X$ whereas differential privacy is not.\n",
    "\n",
    "For example consider the uniform and point distrubtions as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pi1\n",
      " [0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704] \n",
      "\n",
      "pi2\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "pi1 = probab.uniform(num_persons ** num_values)\n",
    "print(\"pi1\\n\", pi1, \"\\n\")\n",
    "pi2 = probab.point(num_persons ** num_values)\n",
    "print(\"pi2\\n\", pi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we measure the information leakage thrgouh QIF for both cases we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIF posterior vulnerability for p1: 0.09259259259259259\n",
      "QIF posterior vulnerability for p2: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"QIF posterior vulnerability for p1:\", measure.bayes_vuln.posterior(pi1, C))\n",
    "print(\"QIF posterior vulnerability for p2:\", measure.bayes_vuln.posterior(pi2, C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But differential privacy does not consider the prior distribution of $X$, so we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon for pi1: 3.295836866004329\n",
      "Differential Privacy epsilon for pi2: 3.295836866004329\n"
     ]
    }
   ],
   "source": [
    "print(\"Differential Privacy epsilon for pi1:\", get_worst_epsilon(C))\n",
    "print(\"Differential Privacy epsilon for pi2:\", get_worst_epsilon(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is also obvious from the fact that the `get_worst_epsilon` function does not take a `pi` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another difference between the two is that QIF vulnerability is defined as the result of averagind the contribution of all the columns to the vulnerability, while differential privacy represents the worst case (i.e.the maximum $\\epsilon$ for all $z$).\n",
    "\n",
    "Hence there could be a column with a very high $\\epsilon$ value which does not contribute very much to the average (typically because the corresponding output has very low probability). In that case, the QIF vulnerability could be very small, and still $\\epsilon$-differential privacy would have a really big $\\epsilon$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating ideas from QIF into Differential Privacy\n",
    "\n",
    "It is interesting to notice that since differential privacy does not take into account the prior distribution, we could use a prior uniform distribution, which assumes no special knowledge about $X$, and then compute the epsilon parameter from the posterior distributions matrix like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon: 3.2958368660043296\n"
     ]
    }
   ],
   "source": [
    "pi = probab.uniform(num_persons ** num_values)\n",
    "posteriors = channel.hyper(C, pi)[1]\n",
    "print(\"Differential Privacy epsilon:\", get_worst_epsilon(posteriors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel matrix $C$ and the matrix of the posterior distributions give the same epsilon values for all columns. Compare them with the results we got before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon for column 0 = 3.2958368660043296\n",
      "epsilon for column 1 = 2.1972245773362196\n",
      "epsilon for column 2 = 2.1972245773362196\n",
      "epsilon for column 3 = 3.2958368660043296\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_values+1):\n",
    "    print(\"epsilon for column\", i, \"=\", get_worst_epsilon(posteriors, column=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if for some reason there is a need to take the prior distribution into account, we could define `pi` and `C` and compute the epsilon value from the matrix of the posterior distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to address the second difference we mentioned before between the two methods, it would be interesting to consider instead of taking the worst-case $\\epsilon$ for all columns, that by weighing the $\\epsilon$ values with the outer probabilities (i.e. the probability of each $z$ happening), then we would not let low-probability high-impact $\\epsilon$ affect too much the general leakage of our channel.\n",
    "\n",
    "That is, we could compute $\\epsilon$ as follows.\n",
    "\n",
    "$$\n",
    "\\epsilon = p_Y(y_0) \\cdot \\epsilon_0 + p_Y(y_1) \\cdot \\epsilon_1 + p_Y(y_2) \\cdot \\epsilon_2 + p_Y(y_3) \\cdot \\epsilon_3\n",
    "$$\n",
    "\n",
    "Again, if we don't want to incorporate any special knowledge about the prior distribution we could assume the uniform distribution.\n",
    "\n",
    "So the new epsilon for our example would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differential Privacy epsilon: 2.7261860496579025\n"
     ]
    }
   ],
   "source": [
    "outers = channel.hyper(C, pi)[0]\n",
    "e = 0\n",
    "\n",
    "for i in range(num_values+1):\n",
    "    e += outers[i] * get_worst_epsilon(posteriors, column=i)\n",
    "\n",
    "print(\"Differential Privacy epsilon:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is obviously lower than the usual $\\epsilon$ since that one represents the worst case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
