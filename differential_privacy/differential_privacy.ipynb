{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Differential Privacy_ and _Quantitative Information Flow_ can be seen as having essentially the same goal as quantitative information flow, namely to control the leakage of sensitive information. In this notebook, we are going to try to explore similarities and differences bewteen the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from func import *\n",
    "try:\n",
    "    from qif import *\n",
    "except: # install qif if not available (for running in colab, etc)\n",
    "    import IPython; IPython.get_ipython().run_line_magic('pip', 'install qif')\n",
    "    from qif import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example scenario\n",
    "\n",
    "Assume we are interested in the eye color of a certain population $\\cal{I} = \\{Alice,Bob,Charlie\\}$. Let the possible values for each person in $\\cal{I}$ be defined by the set $\\cal{V}=\\{a,b,g\\}$, where $a$ stands for absent (i.e. the person is not in this specific database), $b$ stands for _black_ and $g$ for _green_. Each dataset is a tuple $x_0x_1x_2 \\in \\cal{V}^2$ where $x_0$ represents the eye color of _Alice_, $x_1$ of _Bob_ and $x_2$ of _Charlie_. \n",
    "\n",
    "So we have\n",
    "\n",
    "```\n",
    "X = { \n",
    "    aaa, aab, aag, \n",
    "    aba, abb, abg,\n",
    "    aga, agb, agg,\n",
    "    baa, bab, bag,\n",
    "         ...\n",
    "    gga, ggb, ggg\n",
    "    }\n",
    "```\n",
    "\n",
    "Consider now a counting query in the form of\n",
    "\n",
    "```\n",
    "SELECT COUNT(*)\n",
    "FROM X\n",
    "WHERE eye_color = 'b';\n",
    "```\n",
    "\n",
    "Its possible output values are\n",
    "\n",
    "```\n",
    "Y = {0, 1, 2, 3}\n",
    "```\n",
    "\n",
    "We can model this query as a channel $f$ as below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "f & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{aaa} & 1 & 0 & 0 & 0  \\\\ \\hline\n",
    "\\texttt{aab} & 0 & 1 & 0 & 0  \\\\ \\hline \n",
    "\\texttt{aag} & 1 & 0 & 0 & 0  \\\\ \\hline \n",
    "\\texttt{aba} & 0 & 1 & 0 & 0  \\\\ \\hline \n",
    "... & ... & ... & ... & ...\\\\ \\hline\n",
    "\\texttt{ggg} & 1 & 0 & 0 & 0  \\\\ \\hline \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Now insted of reporting the true answer $y$, we process it further by passing it through a noise channel $H$ and report a slightly different answer $z$. The domain of $z$ is the same as $Y$, i.e. $Z = Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are gonna use the following mechanism for $H$.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "H & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{0} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{1} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "\\texttt{2} & \\frac{1}{12} & \\frac{1}{6} & \\frac{1}{2} & \\frac{1}{4} \\\\ \\hline\n",
    "\\texttt{3} & \\frac{1}{36} & \\frac{1}{18} & \\frac{1}{6} & \\frac{3}{4} \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "What $H$ does is basically add noise to the true answer of $f$ using a specific logic which is not of importance for this example. The thing to notice is that the true answer of $f$ has the highest probability within its row.\n",
    "\n",
    "So the whole channel, from $X$ to $Z$, i.e. from the database to the fuzzy query answer, can be depicted as below.\n",
    "\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|}\n",
    "\\hline\n",
    "C & \\texttt{0} & \\texttt{1} & \\texttt{2} & \\texttt{3}  \\\\ \\hline\n",
    "\\texttt{aaa} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{aab} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "\\texttt{aag} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline\n",
    "\\texttt{aba} & \\frac{1}{4} & \\frac{1}{2} & \\frac{1}{6} & \\frac{1}{12} \\\\ \\hline\n",
    "... & ... & ... & ... & ...\\\\ \\hline\n",
    "\\texttt{ggg} & \\frac{3}{4} & \\frac{1}{6} & \\frac{1}{18} & \\frac{1}{36} \\\\ \\hline \n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_persons = 3\n",
    "values = ['a', 'b', 'g']\n",
    "num_values = len(values)\n",
    "query_value = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.02777778 0.05555556 0.16666667 0.75      ]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.08333333 0.16666667 0.5        0.25      ]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]\n",
      " [0.25       0.5        0.16666667 0.08333333]\n",
      " [0.75       0.16666667 0.05555556 0.02777778]]\n"
     ]
    }
   ],
   "source": [
    "C = get_C(num_persons, values, query_value)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image graphically depicts the whole setting (ingore the notions of leakage and utility for now).\n",
    "\n",
    "![img1](./img1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesing the information leakage through _QIF_\n",
    "\n",
    "To measure the leakage with _QIF_ we must first define the prior distribution over $X$. If we don't have any particular knowledge about it we use the uniform distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704 0.03703704\n",
      " 0.03703704 0.03703704 0.03703704]\n"
     ]
    }
   ],
   "source": [
    "pi = probab.uniform(num_persons ** num_values)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the hyper distribution which depends both on $H$ and $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|    0.35    0.31    0.21    0.13 |\n",
      "---------------------------------------\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.00    0.01    0.03    0.22 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.01    0.02    0.09    0.07 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "|    0.03    0.06    0.03    0.02 |\n",
      "|    0.08    0.02    0.01    0.01 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from print_hyper import print_hyper\n",
    "print_hyper(C, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each column, i.e. each possible outcome, we model the threat as the $x$ with the highest probability within that column. So we pick the maximum probabilities of each column and then **we weigh** them with the outer probabilities, i.e. the probability of each $z$ occuring. And the result is the vulnerability of $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesing the information leakage through _Differential Privacy_\n",
    "\n",
    "Differential privacy works a bit differently. \n",
    "\n",
    "First of all it uses the notion of _adjacent_ or _neighbor_ databases. That means two databases that they differ in the presence of, or in the value associated with, exactly one individual. We use $x_1∼x_2$ to indicate that $x_1$ and $x_2$ are adjacent. For example $bbg∼bag$ and $aba∼bba$.\n",
    "\n",
    "Now, for each possible outcome $z$, meaning each column of $C$, _Differential Privacy_ models the threat as the biggest difference between two _adjacent_ databases using the following inequality.\n",
    "\n",
    "$$\n",
    "C_{x_1 z} \\leq e^{\\epsilon} \\cdot C_{x_2z}\n",
    "$$\n",
    "\n",
    "where $x_1∼x_2$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
