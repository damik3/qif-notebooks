{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Three Prisoners Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three prisoners, Alice, Bob and Charlie are senteced to death, but one of them (uniformly chosen at random) is selected to be pardoned, so that just the two out of the three prisoners will be executed. The warden knows which one will be pardoned, but he is not allowed to tell the prisoners. Alice begs the warden to let her know the identity of one of the others who will be executed saying: \n",
    "\n",
    "> _\"If Bob is pardoned, say Charlie's name, and if Charlie is pardoned say Bob's. If I'm pardoned, chose randomly to name Bob or Charlie.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given the warden's answer, we are interested in answering two questions:\n",
    "1. What is the probability of correctly guessing the pardoned prisoner?\n",
    "2. Is the warden’s answer useful for Alice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel matrix \n",
    "\n",
    "Let's model this problem using a channel $W$ that takes an input $X$ (the prisoner to be pardoned) and produces an output $Y$ (the warden's answer). You can think of $W$ as being the warden in our problem. The possible values for $X$ and $Y$ are $A, B, C$ (short for Alice, Bob and Charlie). Notice that the warden will never say Alice's name, but still for the more general case we include it. $W$ is defined as\n",
    "\n",
    "$$\n",
    "W = \\left( \\begin{array} {ccc}\n",
    "    p(Y=A | X=A) & p(Y=B | X=A) & p(Y=C | X=A) \\\\\n",
    "    p(Y=A | X=B) & p(Y=B | X=B) & p(Y=C | X=B) \\\\\n",
    "    p(Y=A | X=C) & p(Y=B | X=C) & p(Y=C | X=C) \\\\\n",
    "\\end{array} \\right) \n",
    "$$\n",
    "\n",
    "\n",
    "or in our case\n",
    "\n",
    "$$ \n",
    "W = \\left( \\begin{array} {cc}\n",
    "    0 & \\frac{1}{2} & \\frac{1}{2} \\\\\n",
    "    0 & 0 & 1 \\\\\n",
    "    0 & 1 & 0 \\\\\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "$W$'s first row corresponds to $X=A$, meaning the scenario where Alice is chosen to be pardoned. In that case the channel's output (or the warden's saying) is not deterministic, but has some degree of randomness. More specifically the warden says Alice with probability $0$, and chooses uniformly between Bob and Charlie, that is, with probability $\\frac{1}{2}$ each. \n",
    "\n",
    "$W$'s second row corresponds to $X=B$, meaning the scenario where Bob is chosen to be pardoned. In that case, there is only one possible output, and that is Charlie. In this case, $W$ (the warden) behaves deterministically and this can be seen because the second row of $W$ has $0$ everywhere, except for one specific output, which gets probability $1$. Same happens with the third row, which corresponds to $X=C$, meaning Charlie is chosen to be pardoned.\n",
    "\n",
    "Notice that each row of $W$ sums up to $1$. This happens because each row defines a probability distribution, which basically says how $W$ (the warden) behaves given a specific input $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define $W$ using python and libqif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from qif import *\n",
    "except: # install qif if not available (for running in colab, etc)\n",
    "    import IPython; IPython.get_ipython().run_line_magic('pip', 'install qif')\n",
    "    from qif import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([\n",
    "    # Y=A  Y=B  Y=C\n",
    "    [   0, 1/2, 1/2],    # X=A\n",
    "    [   0,   0,   1],    # X=B\n",
    "    [   0,   1,   0],    # X=C\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to answer Question 1 using QIF terminology, we want to find the **posterior vulnerability** of $W$. That is, what is the probability of correctly guessing the secret $X$ after observing the channel's output $Y$. Let's see how we can compute that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior distribution \n",
    "\n",
    "First of all we must define the distribution of $X$. It is also called *the prior distribution* $\\pi$. In our case that is the probability of each prisoner being pardoned. The problem states that it is uniform, so we have\n",
    "\n",
    "$$\n",
    "p(X=A) = p(X=B) = p(X=C) = \\frac{1}{3} \n",
    "$$\n",
    "\n",
    "or for short\n",
    "\n",
    "$$\n",
    "\\pi = (\\frac{1}{3},\\frac{1}{3}, \\frac{1}{3}) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Matrix\n",
    "\n",
    "Next, we compute $J$, which is defined as\n",
    "\n",
    "$$ \n",
    "J = \\left( \\begin{array} {ccc}\n",
    "    p(Y=A \\textit{ and } X=A) & p(Y=B \\textit{ and } X=A) & p(Y=C \\textit{ and } X=A) \\\\\n",
    "    p(Y=A \\textit{ and } X=B) & p(Y=B \\textit{ and } X=B) & p(Y=C \\textit{ and } X=B) \\\\\n",
    "    p(Y=A \\textit{ and } X=C) & p(Y=B \\textit{ and } X=C) & p(Y=C \\textit{ and } X=C) \\\\\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "$J$ contains the joint probabilities for each combination of $X$ and $Y$. For computing $J$, we use the rule $p_{Y,X}(y,x) = p_X(x) \\cdot p_{Y|X}(y|x) $.\n",
    "\n",
    "$$ \n",
    "J = \\left( \\begin{array} {ccc}\n",
    "    p(X=A) \\cdot p(Y=A | X=A) & p(X=A) \\cdot p(Y=B | X=A) & p(X=A) \\cdot p(Y=C | X=A) \\\\ \n",
    "    p(X=B) \\cdot p(Y=A | X=B) & p(X=B) \\cdot p(Y=B | X=B) & p(X=B) \\cdot p(Y=C | X=B) \\\\\n",
    "    p(X=C) \\cdot p(Y=A | X=C) & p(X=C) \\cdot p(Y=B | X=C) & p(X=C) \\cdot p(Y=C | X=C) \\\\\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "Notice that $J$ depends on the channel $W$, **but also** on the distribution $\\pi$ of $X$. Meaning that it depends on all of the $p(X=A)$, $p(X=B)$, $p(X=C)$. Thus, if the pardoned prisoner were not chosen at random (meaning $\\pi$ was different), then $J$ would be different.\n",
    "\n",
    "If we compute $J$ for our case, it becomes\n",
    "\n",
    "$$ \n",
    "J = \\left( \\begin{array} {cc}\n",
    "    0 & \\frac{1}{6} & \\frac{1}{6} \\\\\n",
    "    0 & 0 & \\frac{1}{3} \\\\\n",
    "    0 & \\frac{1}{3} & 0 \\\\\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "See that if we sum all of $J$'s elements they add up to 1. That is excpected because by the defitition of probabiliy, when we sum the probabilities of every possible outcume, they must add up to 1. And that is exactly what happens when we sum $J$'s elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior Distributions\n",
    "But we're most interested in *what exactly* does the warden's saying ($W$'s output) tells us about $X$.\n",
    "\n",
    "To answer this, we define $P$ as\n",
    "\n",
    "$$ \n",
    "P = \\left( \\begin{array} {ccc}\n",
    "    p(X=A | Y=A) & p(X=A | Y=B) & p(X=A | Y=C) \\\\\n",
    "    p(X=B | Y=A) & p(X=B | Y=B) & p(X=B | Y=C) \\\\\n",
    "    p(X=C | Y=A) & p(X=C | Y=B) & p(X=C | Y=C) \\\\\n",
    "\\end{array} \\right) \n",
    "$$\n",
    "\n",
    "Take a moment to compare it with $W$. It seems similar. Except that the $X$'s and the $Y$'s have \"switched places\" over the vertical line.\n",
    "\n",
    "$P$'s first column gives us the probabilities of each prisoner being pardoned, **given that** the warden has said Alice's name. That is, the probability of $X$ being $A, B$ or $C$, **given that** $W$'s output is $A$. The same happens with the second and the third column.\n",
    "\n",
    "Notice that each column gives us a new probability distribution (also meaning that each column adds up to 1). That is, it tells us the **updated** probability  of each $X$ **after** observing $W$'s output.\n",
    "\n",
    "$P$ can be computed using the rules $p(y) = \\sum_{x} p_{X, Y}(x, y)$ and $p_{X|Y}(x|y) = \\frac{p_{X, Y}(x, y)}{p_Y(y)}$.\n",
    "\n",
    "In our case, it becomes\n",
    "\n",
    "$$ \n",
    "P = \\left( \\begin{array} {cc}\n",
    "    0 & \\frac{1}{3} & \\frac{1}{3} \\\\\n",
    "    0 & 0 & \\frac{2}{3} \\\\\n",
    "    0 & \\frac{2}{3} & 0 \\\\\n",
    "\\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally solving the problem\n",
    "\n",
    "#### Question 2\n",
    "\n",
    "We are now ready to answer the two questions we set for ourselves. First we will answer the question number 2 which asks\n",
    "\n",
    ">Is the warden’s answer useful for Alice?\n",
    "\n",
    "Before hearing the warden's saying ($W$'s output), Alice knew that she had a $\\frac{1}{3}$ probability of surviving (becuase the pardoned prisoner were chosen uniformly at random).\n",
    "\n",
    "Now, using matrix $P$, we know that if the warden says Bob's name ($P$'s second column) then Alice has a $p(X=A | Y=B) = \\frac{1}{3}$ ($P$'s second column **and** $P$'s first row) probability of surviving. \n",
    "\n",
    "With the same reasoning, we see that if the warden says Charlie's name ($P$'s third column) then Alice has a $p(X=A | Y=C) = \\frac{1}{3}$ ($P$'s third column **and** $P$'s first row) probability of surviving.\n",
    "\n",
    "Notice that the warden never says Alice's name ($W$ never outputs $A$) and this can be seen by verifying that $p_Y(A) = 0$.\n",
    "\n",
    "So before the warden's answer, Alice survived with a probability of $\\frac{1}{3}$. After the warden's answer, no matter which name the warden says, Alice **again** survives with a probabiliy of $\\frac{1}{3}$.\n",
    "\n",
    "Looks like Alice should have picked her question more carefully, because *the warden's answer is never useful for Alice*.\n",
    "\n",
    "We can also easily compute that using libqif.\n",
    "\n",
    "#### Question 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
